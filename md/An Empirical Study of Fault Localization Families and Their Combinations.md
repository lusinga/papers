# An Empirical Study of Fault Localization Families and Their Combinations

## Abstract

The performance of fault localization techniques is critical to their adoption in practice. This paper reports on an empirical study of a wide range of fault localization techniques on real-world faults. Different from previous studies, this paper (1) considers a wide range of techniques from different families, (2) combines different techniques, and (3) considers the execution time of different techniques. Our results reveal that combined technique significantly outperforms any individual technique (200% increase in defects localized in Top 1), suggesting that combination may be a desirable way to apply fault localization techniques and future techniques should also be evaluated in the combined setting. Our implementation is publicly available for evaluating and combining fault localization techniques.

æ•…éšœå®šä½æŠ€æœ¯çš„æ€§èƒ½æ˜¯æ•…éšœå®šä½æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„å…³é”®ã€‚æœ¬æ–‡å¯¹å®é™…æ•…éšœçš„å¤šç§æ•…éšœå®šä½æŠ€æœ¯è¿›è¡Œäº†å®è¯ç ”ç©¶ã€‚ä¸ä»¥å¾€çš„ç ”ç©¶ä¸åŒï¼Œæœ¬æ–‡(1)è€ƒè™‘äº†æ¥è‡ªä¸åŒå®¶æ—çš„å¹¿æ³›çš„æŠ€æœ¯ï¼Œ(2)ç»“åˆäº†ä¸åŒçš„æŠ€æœ¯ï¼Œ(3)è€ƒè™‘äº†ä¸åŒæŠ€æœ¯çš„æ‰§è¡Œæ—¶é—´ã€‚æˆ‘ä»¬çš„ç»“æœæ˜¾ç¤ºï¼Œç»„åˆæŠ€æœ¯çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºä»»ä½•å•ç‹¬çš„æŠ€æœ¯(å‰1é¡¹ä¸­çš„ç¼ºé™·å¢åŠ äº†200%)ï¼Œè¿™è¡¨æ˜ç»„åˆå¯èƒ½æ˜¯åº”ç”¨æ•…éšœå®šä½æŠ€æœ¯çš„ç†æƒ³æ–¹æ³•ï¼Œå¹¶ä¸”æœªæ¥çš„æŠ€æœ¯ä¹Ÿåº”è¯¥åœ¨ç»„åˆè®¾ç½®ä¸­è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬çš„å®ç°å…¬å¼€å¯ç”¨æ¥è¯„ä¼°å’Œç»„åˆæ•…éšœå®šä½æŠ€æœ¯ã€‚

## 1 INTRODUCTION

THE goal of fault localization is to identify the defective program elements related to software failures. Manual fault localization is a notoriously time-consuming and tedious task that depends on the programmerâ€™s experience and analysis. Automated fault localization uses static and run-time information about the program (test coverage, program dependency, test output, execution results of mutated programs, etc.) to identify program elements that may be the root cause of the failure. This paper considers seven families of fault localization techniques, which take as input seven different types of information:

æ•…éšœå®šä½çš„ç›®æ ‡æ˜¯è¯†åˆ«ä¸è½¯ä»¶æ•…éšœç›¸å…³çš„æœ‰ç¼ºé™·çš„ç¨‹åºå…ƒç´ ã€‚æ‰‹åŠ¨æ•…éšœå®šä½æ˜¯ä¸€é¡¹éå¸¸è€—æ—¶å’Œä¹å‘³çš„ä»»åŠ¡ï¼Œå®ƒä¾èµ–äºç¨‹åºå‘˜çš„ç»éªŒå’Œåˆ†æã€‚è‡ªåŠ¨æ•…éšœå®šä½ä½¿ç”¨æœ‰å…³ç¨‹åºçš„é™æ€å’Œè¿è¡Œæ—¶ä¿¡æ¯(æµ‹è¯•è¦†ç›–ç‡ã€ç¨‹åºä¾èµ–æ€§ã€æµ‹è¯•è¾“å‡ºã€çªå˜ç¨‹åºçš„æ‰§è¡Œç»“æœç­‰)æ¥è¯†åˆ«å¯èƒ½æ˜¯æ•…éšœçš„æ ¹æœ¬åŸå› çš„ç¨‹åºå…ƒç´ ã€‚æœ¬æ–‡è€ƒè™‘äº†ä¸ƒç§æ•…éšœå®šä½æŠ€æœ¯ï¼Œå°†ä¸ƒç§ä¸åŒç±»å‹çš„ä¿¡æ¯ä½œä¸ºè¾“å…¥:

- Spectrum-based fault localization (SBFL) [1], [2], [3]: utilizing test coverage information 
- Mutation-based fault localization (MBFL) [4], [5]: utilizing test results collected from mutating the program  
- (Dynamic) program slicing [6], [7]: utilizing the dynamic program dependency  
- Stack trace analysis [8], [9]: utilizing error messages 
- Predicate switching [10]: utilizing test results from mutating the results of conditional expressions  
- Information retrieval-based fault localization (IRbased FL) [11]: utilizing bug report information  
- History-based fault localization [12], [13]: utilizing the development history

SBFL
[
- [1] X. Xie, T. Y. Chen, F.-C. Kuo, and B. Xu, â€œA theoretical analysis of the risk evaluation formulas for spectrum-based fault localization,â€ ACM Transactions on Software Engineering and Methodology (TOSEM), vol. 22, no. 4, p. 31, 2013. 
- [2] R. Abreu, P. Zoeteweij, and A. J. Van Gemund, â€œOn the accuracy of spectrum-based fault localization,â€ in Testing: Academic and Industrial Conference Practice and Research Techniques-MUTATION, 2007. TAICPART-MUTATION 2007. IEEE, 2007, pp. 89â€“98. 
- [3] M. J. Harrold, G. Rothermel, K. Sayre, R.Wu, and L. Yi, â€œAn empirical investigation of the relationship between spectra differences and regression faults,â€ Software Testing Verification and Reliability, vol. 10, no. 3, pp. 171â€“194, 2000.
]
[
- [4] M. Papadakis and Y. Le Traon, â€œMetallaxis-fl: mutation-based fault localization,â€ Software Testing, Verification and Reliability, vol. 25, no. 5-7, pp. 605â€“628, 2015. 
- [5] S. Moon, Y. Kim, M. Kim, and S. Yoo, â€œAsk the mutants: Mutating faulty programs for fault localization,â€ in Software Testing, Verification and Validation (ICST), 2014 IEEE Seventh International Conference on. IEEE, 2014, pp. 153â€“162.
]
- [6] H. Agrawal, J. R. Horgan, S. London, and W. E. Wong, â€œFault localization using execution slices and dataflow tests,â€ in Software Reliability Engineering, 1995. Proceedings., Sixth International Symposium on. IEEE, 1995, pp. 143â€“151. 
- [7] M. Renieres and S. P. Reiss, â€œFault localization with nearest neighbor queries,â€ in Automated Software Engineering, 2003. Proceedings. 18th IEEE International Conference on. IEEE, 2003, pp. 30â€“39.

- [8] C.-P. Wong, Y. Xiong, H. Zhang, D. Hao, L. Zhang, and H. Mei, â€œBoosting bug-report-oriented fault localization with segmentation and stack-trace analysis,â€ in Software Maintenance and Evolution (ICSME), 2014 IEEE International Conference on. IEEE, 2014, pp. 181â€“190. 
- [9] R. Wu, H. Zhang, S.-C. Cheung, and S. Kim, â€œCrashlocator: locating crashing faults based on crash stacks,â€ in Proceedings of the 2014 International Symposium on Software Testing and Analysis. ACM, 2014, pp. 204â€“214.

- [10] X. Zhang, N. Gupta, and R. Gupta, â€œLocating faults through automated predicate switching,â€ in International Conference on Software Engineering, 2006, pp. 272â€“281. 
- [11] J. Zhou, H. Zhang, and D. Lo, â€œWhere should the bugs be fixed? more accurate information retrieval-based bug localization based on bug reports,â€ in Software Engineering (ICSE), 2012 34th International Conference on. IEEE, 2012, pp. 14â€“24. 
- [12] S. Kim, T. Zimmermann, E. J. Whitehead Jr, and A. Zeller, â€œPredicting faults from cached history,â€ in Proceedings of the 29th international conference on Software Engineering. IEEE Computer Society, 2007, pp. 489â€“498. 
- [13] F. Rahman, D. Posnett, A. Hindle, E. Barr, and P. Devanbu, â€œBugcache for inspections: hit or miss?â€ in Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering. ACM, 2011, pp. 322â€“331.

- åŸºäºé¢‘è°±çš„æ•…éšœå®šä½(SBFL)[1]ï¼Œ[2]ï¼Œ[3]:åˆ©ç”¨æµ‹è¯•è¦†ç›–ä¿¡æ¯
- åŸºäºçªå˜çš„æ•…éšœå®šä½(MBFL)[4]ï¼Œ[5]:åˆ©ç”¨ä»ç¨‹åºçªå˜ä¸­æ”¶é›†çš„æµ‹è¯•ç»“æœ
- (åŠ¨æ€)ç¨‹åºåˆ‡ç‰‡[6]ï¼Œ[7]:åˆ©ç”¨åŠ¨æ€ç¨‹åºä¾èµ–
- å †æ ˆè·Ÿè¸ªåˆ†æ[8]ï¼Œ[9]:åˆ©ç”¨é”™è¯¯æ¶ˆæ¯
- è°“è¯åˆ‡æ¢[10]:åˆ©ç”¨æµ‹è¯•ç»“æœçªå˜çš„ç»“æœçš„æ¡ä»¶è¡¨è¾¾å¼
- åŸºäºä¿¡æ¯æ£€ç´¢çš„æ•…éšœå®šä½(IRbased FL)[11]:åˆ©ç”¨é”™è¯¯æŠ¥å‘Šä¿¡æ¯
- åŸºäºå†å²çš„æ•…éšœå®šä½[12]ï¼Œ[13]:åˆ©ç”¨å¼€å‘å†å²

Some techniques compute a suspiciousness score for each program element and can generate a ranked list of elements, such as spectrum-based fault localization. Other techniques only mark a set of elements as suspicious, such as dynamic program slicing.

ä¸€äº›æŠ€æœ¯ä¸ºæ¯ä¸ªç¨‹åºå…ƒç´ è®¡ç®—ä¸€ä¸ªå¯ç–‘æ€§è¯„åˆ†ï¼Œå¹¶å¯ä»¥ç”Ÿæˆä¸€ä¸ªå…ƒç´ çš„æ’åºåˆ—è¡¨ï¼Œä¾‹å¦‚åŸºäºé¢‘è°±çš„æ•…éšœå®šä½ã€‚å…¶ä»–æŠ€æœ¯åªå°†ä¸€ç»„å…ƒç´ æ ‡è®°ä¸ºå¯ç–‘çš„ï¼Œæ¯”å¦‚åŠ¨æ€ç¨‹åºåˆ‡ç‰‡ã€‚

The performance of fault localization is critical to its adoption in practice. Fault localization techniques are helpful only when the root causes are ranked at a high absolute position [14], [15]; the position should be within the top 5 [16]. A number of empirical studies [17], [18], [19], [20] have evaluated the performance of SBFL and MBFL. However, no empirical study has evaluated the performance of other techniques on real-world defects, as far as we know.

æ•…éšœå®šä½çš„æ€§èƒ½æ˜¯æ•…éšœå®šä½åœ¨å®é™…åº”ç”¨ä¸­çš„å…³é”®ã€‚æ•…éšœå®šä½æŠ€æœ¯åªæœ‰åœ¨æ ¹æœ¬åŸå› å¤„äº[14]ã€[15]è¾ƒé«˜çš„ç»å¯¹ä½ç½®æ—¶æ‰æœ‰å¸®åŠ©;ä½ç½®åº”è¯¥åœ¨å‰5[16]ä»¥å†…ã€‚[17]ã€[18]ã€[19]ã€[20]ç­‰å¤šé¡¹å®è¯ç ”ç©¶å¯¹SBFLå’ŒMBFLçš„æ€§èƒ½è¿›è¡Œäº†è¯„ä»·ã€‚ç„¶è€Œï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿˜æ²¡æœ‰å®è¯ç ”ç©¶è¯„ä¼°å…¶ä»–æŠ€æœ¯åœ¨çœŸå®ç¼ºé™·ä¸Šçš„æ€§èƒ½ã€‚

This paper reports on an empirical study of fault localization techniques. Our study aims to include a wide range of fault localization techniques from different families, including SBFL, MBFL, program slicing, predicate switching, stack trace analysis, information retrieve-based fault localization, and history-based fault localization. Following the insight from existing work [17] that the performance of fault localization techniques may differ between real faults and artificial faults, our study is based on 357 real-world faults from the Defects4J dataset [21].

æœ¬æ–‡å¯¹æ•…éšœå®šä½æŠ€æœ¯è¿›è¡Œäº†å®è¯ç ”ç©¶ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ—¨åœ¨åŒ…æ‹¬æ¥è‡ªä¸åŒå®¶æ—çš„å¹¿æ³›çš„æ•…éšœå®šä½æŠ€æœ¯ï¼ŒåŒ…æ‹¬SBFLã€MBFLã€ç¨‹åºåˆ‡ç‰‡ã€è°“è¯åˆ‡æ¢ã€å †æ ˆè·Ÿè¸ªåˆ†æã€åŸºäºä¿¡æ¯æ£€ç´¢çš„æ•…éšœå®šä½å’ŒåŸºäºå†å²çš„æ•…éšœå®šä½ã€‚æ ¹æ®ç°æœ‰å·¥ä½œ[17]çš„è§‚ç‚¹ï¼Œæ•…éšœå®šä½æŠ€æœ¯çš„æ€§èƒ½å¯èƒ½åœ¨çœŸå®æ•…éšœå’Œäººå·¥æ•…éšœä¹‹é—´æœ‰æ‰€ä¸åŒï¼Œæˆ‘ä»¬çš„ç ”ç©¶åŸºäºæ¥è‡ªäºDefects4Jæ•°æ®é›†[21]çš„357ä¸ªçœŸå®æ•…éšœã€‚

In contrast to previous studies, our study explores mainly two novelty aspects. First, since techniques in different families use different information sources, it is interesting to know how much these techniques are correlated to each other. We measured the correlation between different pairs of techniques and explored the possibility of combining these techniques using learning to rank model [22]. In contrast, previous work usually considers techniques in one or a few families, e.g., combining different formulae in SBFL [23] or combining SBFL and history-based techniques [25], and our work is the first to explore the combinations of a wide range of techniques that rely on different information sources.

ä¸ä»¥å¾€çš„ç ”ç©¶ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä¸»è¦æ¢ç´¢äº†ä¸¤ä¸ªæ–°é¢–æ€§æ–¹é¢ã€‚é¦–å…ˆï¼Œç”±äºä¸åŒå®¶åº­ä¸­çš„æŠ€æœ¯ä½¿ç”¨ä¸åŒçš„ä¿¡æ¯æºï¼Œæ‰€ä»¥äº†è§£è¿™äº›æŠ€æœ¯ä¹‹é—´çš„ç›¸äº’å…³ç³»æ˜¯å¾ˆæœ‰è¶£çš„ã€‚æˆ‘ä»¬æµ‹é‡äº†ä¸åŒæŠ€æœ¯å¯¹ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶æ¢ç´¢äº†åˆ©ç”¨å­¦ä¹ å¯¹æ¨¡å‹[22]è¿›è¡Œæ’åºæ¥ç»“åˆè¿™äº›æŠ€æœ¯çš„å¯èƒ½æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä»¥å‰çš„å·¥ä½œé€šå¸¸åªè€ƒè™‘ä¸€ä¸ªæˆ–å‡ ä¸ªç³»åˆ—çš„æŠ€æœ¯ï¼Œä¾‹å¦‚ï¼Œç»„åˆSBFL[23]ä¸­çš„ä¸åŒå…¬å¼æˆ–ç»„åˆSBFLå’ŒåŸºäºå†å²çš„æŠ€æœ¯[25]ï¼Œè€Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯ç¬¬ä¸€ä¸ªæ¢ç´¢ä¾èµ–äºä¸åŒä¿¡æ¯æºçš„å„ç§æŠ€æœ¯çš„ç»„åˆã€‚

The second novelty is that we measured the time cost of different fault localization techniques. Existing studies have shown that efficiency and scalability are both critical to the adoption of fault localization techniques [16]. Thus, a good fault localization approach must balance between localization performance and cost. We have considered different usage scenarios to find the best balance in practice.

ä¸ä»¥å¾€çš„ç ”ç©¶ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä¸»è¦æ¢ç´¢äº†ä¸¤ä¸ªæ–°é¢–æ€§æ–¹é¢ã€‚é¦–å…ˆï¼Œç”±äºä¸åŒå®¶åº­ä¸­çš„æŠ€æœ¯ä½¿ç”¨ä¸åŒçš„ä¿¡æ¯æºï¼Œæ‰€ä»¥äº†è§£è¿™äº›æŠ€æœ¯ä¹‹é—´çš„ç›¸äº’å…³ç³»æ˜¯å¾ˆæœ‰è¶£çš„ã€‚æˆ‘ä»¬æµ‹é‡äº†ä¸åŒæŠ€æœ¯å¯¹ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶æ¢ç´¢äº†åˆ©ç”¨å­¦ä¹ å¯¹æ¨¡å‹[22]è¿›è¡Œæ’åºæ¥ç»“åˆè¿™äº›æŠ€æœ¯çš„å¯èƒ½æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä»¥å‰çš„å·¥ä½œé€šå¸¸åªè€ƒè™‘ä¸€ä¸ªæˆ–å‡ ä¸ªç³»åˆ—çš„æŠ€æœ¯ï¼Œä¾‹å¦‚ï¼Œç»„åˆSBFL[23]ä¸­çš„ä¸åŒå…¬å¼æˆ–ç»„åˆSBFLå’ŒåŸºäºå†å²çš„æŠ€æœ¯[25]ï¼Œè€Œæˆ‘ä»¬çš„å·¥ä½œæ˜¯ç¬¬ä¸€ä¸ªæ¢ç´¢ä¾èµ–äºä¸åŒä¿¡æ¯æºçš„å„ç§æŠ€æœ¯çš„ç»„åˆã€‚

Finally, we have released our experimental infrastructure. This experimental infrastructure can be used by other researchers to evaluate fault localization techniques and to combine different fault localization techniques.

æœ€åï¼Œæˆ‘ä»¬å‘å¸ƒäº†æˆ‘ä»¬çš„å®éªŒåŸºç¡€è®¾æ–½ã€‚è¿™ä¸ªå®éªŒåŸºç¡€è®¾æ–½å¯ä»¥è¢«å…¶ä»–ç ”ç©¶äººå‘˜ç”¨æ¥è¯„ä¼°æ•…éšœå®šä½æŠ€æœ¯ï¼Œå¹¶ç»“åˆä¸åŒçš„æ•…éšœå®šä½æŠ€æœ¯ã€‚

Our study has the following main findings: 
- On real-world faults, all techniques except for Bugspots localize more than 6% faults at top 10, while the best family, SBFL, localizes about 44% faults at top 10. 
- Most techniques in our study have a weak correlation, especially those in different families, indicating the potential of combining them. 
- Combining techniques improves performance significantly: 200/63/51/31% increase in top 1/3/5/10 localized defects, and 48% decrease in examined elements compared to the best standalone technique. 
- This combined technique also outperforms the four state-of-art fault localization approaches, MULTRIC [23], Savant [24], FLUCCS [25], and TraPT [26] by 133%, 167%, 11% and 18% in Top 1 correspondingly. 
- Time costs of different fault localization families can be categorized into several levels. When using a technique at one time cost level, it does not affect run time, but does improve fault localization effectiveness, to include all techniques from the preceding levels. 
- The above findings hold at both statement and method granularities â€” that is, when the FL technique is identifying suspicious statements and when it is identifying suspicious methods.

[
- [23] J. Xuan and M. Monperrus, â€œLearning to combine multiple ranking metrics for fault localization,â€ in Software Maintenance and Evolution (ICSME), 2014 IEEE International Conference on. IEEE, 2014, pp. 191â€“200.
- [24] T.-D. B Le, D. Lo, C. Le Goues, and L. Grunske, â€œA learning-torank based fault localization approach using likely invariants,â€ in Proceedings of the 25th International Symposium on Software Testing and Analysis. ACM, 2016, pp. 177â€“188. 
- [25] J. Sohn and S. Yoo, â€œFluccs: using code and change metrics to improve fault localization,â€ in Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis. ACM, 2017, pp. 273â€“283.
- [26] X. Li and L. Zhang, â€œTransforming programs and tests in tandem for fault localization,â€
]

æˆ‘ä»¬çš„ç ”ç©¶æœ‰ä»¥ä¸‹ä¸»è¦å‘ç°:

- åœ¨çœŸå®ä¸–ç•Œçš„æ•…éšœä¸­ï¼Œé™¤äº†æ•…éšœç‚¹ä»¥å¤–çš„æ‰€æœ‰æŠ€æœ¯éƒ½å°†6%ä»¥ä¸Šçš„æ•…éšœå®šä½åœ¨å‰10ä½ï¼Œè€Œæœ€å¥½çš„å®¶æ—SBFLå°†44%çš„æ•…éšœå®šä½åœ¨å‰10ä½ã€‚
- æˆ‘ä»¬ç ”ç©¶çš„å¤§å¤šæ•°æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ä¸åŒå®¶åº­çš„æŠ€æœ¯ï¼Œç›¸å…³æ€§è¾ƒå¼±ï¼Œè¡¨æ˜å®ƒä»¬æœ‰ç»“åˆçš„æ½œåŠ›ã€‚
- ç»„åˆæŠ€æœ¯æ˜¾è‘—æé«˜äº†æ€§èƒ½:ä¸æœ€å¥½çš„å•æœºæŠ€æœ¯ç›¸æ¯”ï¼Œå‰1/3/5/10å±€éƒ¨ç¼ºé™·å¢åŠ äº†200/63/51/31%ï¼Œæ£€æµ‹å…ƒç´ å‡å°‘äº†48%ã€‚
- è¯¥ç»„åˆæŠ€æœ¯ä¹Ÿæ¯”å››ç§æœ€å…ˆè¿›çš„æ•…éšœå®šä½æ–¹æ³•MULTRIC[23]ã€Savant[24]ã€cs[25]å’ŒTraPT[26]åˆ†åˆ«é«˜å‡º133%ã€167%ã€11%å’Œ18%ã€‚
- ä¸åŒæ•…éšœå®šä½æ—çš„æ—¶é—´æˆæœ¬å¯ä»¥åˆ†ä¸ºå‡ ä¸ªå±‚æ¬¡ã€‚å½“åœ¨ä¸€ä¸ªæ—¶é—´æˆæœ¬çº§åˆ«ä¸Šä½¿ç”¨ä¸€ç§æŠ€æœ¯æ—¶ï¼Œå®ƒä¸ä¼šå½±å“è¿è¡Œæ—¶ï¼Œä½†æ˜¯ä¼šæé«˜æ•…éšœå®šä½çš„æ•ˆç‡ï¼ŒåŒ…æ‹¬å‰é¢çº§åˆ«çš„æ‰€æœ‰æŠ€æœ¯ã€‚
- ä¸Šè¿°å‘ç°åŒæ—¶é€‚ç”¨äºè¯­å¥å’Œæ–¹æ³•çš„ç²’åº¦-å³å½“FLæŠ€æœ¯è¯†åˆ«å¯ç–‘è¯­å¥æ—¶å’Œå½“å®ƒè¯†åˆ«å¯ç–‘æ–¹æ³•æ—¶ã€‚

To sum up, the paper makes the following contributions.
- The first empirical study that compares a wide range of fault localization techniques on real faults. 
- A combined technique that is configurable based on the time cost, and the peak performance of the technique significantly outperforms single techniques. 
- An infrastructure for evaluating and combining fault localization techniques for future research.

ç»¼ä¸Šæ‰€è¿°ï¼Œæœ¬æ–‡çš„è´¡çŒ®å¦‚ä¸‹:

- ç¬¬ä¸€æ¬¡å®è¯ç ”ç©¶ï¼Œæ¯”è¾ƒå¤§èŒƒå›´çš„æ•…éšœå®šä½æŠ€æœ¯å¯¹å®é™…æ•…éšœã€‚
- åŸºäºæ—¶é—´æˆæœ¬å¯é…ç½®çš„ç»„åˆæŠ€æœ¯ï¼Œå¹¶ä¸”è¯¥æŠ€æœ¯çš„å³°å€¼æ€§èƒ½æ˜¾è‘—ä¼˜äºå•ä¸ªæŠ€æœ¯ã€‚
- ç”¨äºè¯„ä¼°å’Œç»„åˆæ•…éšœå®šä½æŠ€æœ¯ä»¥ä¾›æœªæ¥ç ”ç©¶çš„åŸºç¡€è®¾æ–½ã€‚

The rest of the paper is organized as follows. Section 2 introduces the background of several fault localization families. Section 3 presents the empirical evaluation setups. Section 4 shows the experiment results and answers the research questions. Section 5 discusses the related studies. Section 6 discusses the implications for future research. And Section 7 concludes.

## 2 BACKGROUND

Commonly, a fault localization technique takes as input a faulty program and a set of test cases with at least one failed test, and generates as output a potentially ranked list of suspicious program elements. Recently, some approaches [11], [13], [27] considered other input information, such as the bug report or the develop history. This paper also considers these approaches. The common levels of granularity for program elements are statements, methods, and files. This paper uses statements as program elements, except for Section 4.5 which compares results for different granularities.

é€šå¸¸ï¼Œæ•…éšœå®šä½æŠ€æœ¯å°†é”™è¯¯çš„ç¨‹åºå’Œä¸€ç»„è‡³å°‘æœ‰ä¸€ä¸ªå¤±è´¥æµ‹è¯•çš„æµ‹è¯•ç”¨ä¾‹ä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆå¯ç–‘ç¨‹åºå…ƒç´ çš„æ½œåœ¨æ’åºåˆ—è¡¨ä½œä¸ºè¾“å‡ºã€‚æœ€è¿‘ï¼Œä¸€äº›æ–¹æ³•[11]ã€[13]ã€[27]è€ƒè™‘äº†å…¶ä»–è¾“å…¥ä¿¡æ¯ï¼Œå¦‚é”™è¯¯æŠ¥å‘Šæˆ–å¼€å‘å†å²ã€‚æœ¬æ–‡ä¹Ÿè€ƒè™‘äº†è¿™äº›æ–¹æ³•ã€‚ç¨‹åºå…ƒç´ çš„å¸¸è§ç²’åº¦çº§åˆ«æ˜¯è¯­å¥ã€æ–¹æ³•å’Œæ–‡ä»¶ã€‚æœ¬æ–‡ä½¿ç”¨è¯­å¥ä½œä¸ºç¨‹åºå…ƒç´ ï¼Œé™¤äº†4.5èŠ‚æ¯”è¾ƒäº†ä¸åŒç²’åº¦çš„ç»“æœã€‚

This section first introduces seven families of fault localization techniques, and then introduces the learning to rank model for combining different techniques.

### 2.1 Spectrum-Based Fault Localization

A program spectrum is a measurement of run-time behavior, such as code coverage [3]. Collofello and Cousins proposed that program spectra be used for fault localization [28]. Comparing program spectra on passed and failed test cases enable ranking of program elements. The more frequently an element is executed in failed tests, and the less frequently it is executed in passed tests, the more suspicious the element is.

ç¨‹åºé¢‘è°±æ˜¯å¯¹è¿è¡Œæ—¶è¡Œä¸º(å¦‚ä»£ç è¦†ç›–ç‡[3])çš„åº¦é‡ã€‚Collofelloå’ŒCousinsæå‡ºå°†ç¨‹åºè°±ç”¨äºæ•…éšœå®šä½[28]ã€‚æ¯”è¾ƒé€šè¿‡å’Œå¤±è´¥æµ‹è¯•ç”¨ä¾‹ä¸Šçš„ç¨‹åºè°±å¯ä»¥å¯¹ç¨‹åºå…ƒç´ è¿›è¡Œæ’åºã€‚ä¸€ä¸ªå…ƒç´ åœ¨å¤±è´¥çš„æµ‹è¯•ä¸­æ‰§è¡Œçš„é¢‘ç‡è¶Šé«˜ï¼Œåœ¨é€šè¿‡çš„æµ‹è¯•ä¸­æ‰§è¡Œçš„é¢‘ç‡è¶Šä½ï¼Œè¿™ä¸ªå…ƒç´ å°±è¶Šå¯ç–‘ã€‚

Typically, an SBFL approach calculates suspiciousness scores using a ranking metric [29], or risk evaluation formula [1], [30], based on four values collected from the executions of the tests, as shown in Table 1. For example, Ochiai [2] is an effective SBFL technique [30] using the formula:

$Ochiai(element)=\frac{}{}$

é€šå¸¸ï¼ŒSBFLæ–¹æ³•ä½¿ç”¨æ’ååº¦é‡[29]æˆ–é£é™©è¯„ä¼°å…¬å¼[1]ã€[30]æ¥è®¡ç®—å¯ç–‘æ€§åˆ†æ•°ï¼Œè¯¥å…¬å¼åŸºäºä»æ‰§è¡Œæµ‹è¯•ä¸­æ”¶é›†çš„å››ä¸ªå€¼ï¼Œå¦‚è¡¨1æ‰€ç¤ºã€‚ä¾‹å¦‚ï¼ŒOchiai[2]æ˜¯ä¸€ç§æœ‰æ•ˆçš„SBFLæŠ€æœ¯[30]ï¼Œå…¶å…¬å¼ä¸º:

DStar [31] is another effective technique [17], [32] using
the formula:
DStar (element) =
e
âˆ—
f
ep + nf
DStarâ€™s notation â€˜*â€™ is a variable, which we set to 2 based on
the recommendation from Wong et al. [31].

### 2.2 Mutation-Based Fault Localization

Mutation-based fault localization uses information from mutation analysis [33], rather than from regular program execution, as inputs to its ranking metric or risk evaluation formula. While SBFL techniques consider whether a statement is executed or not, MBFL techniques consider whether the execution of a statement affects the result of a test [17]. If a program statement affects failed tests more frequently and affects passed tests more rarely, it is more suspicious.

åŸºäºçªå˜çš„æ•…éšœå®šä½ä½¿ç”¨æ¥è‡ªçªå˜åˆ†æ[33]çš„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯æ¥è‡ªå¸¸è§„ç¨‹åºæ‰§è¡Œçš„ä¿¡æ¯ï¼Œä½œä¸ºå…¶æ’åæŒ‡æ ‡æˆ–é£é™©è¯„ä¼°å…¬å¼çš„è¾“å…¥ã€‚å½“SBFLæŠ€æœ¯è€ƒè™‘è¯­å¥æ˜¯å¦è¢«æ‰§è¡Œæ—¶ï¼ŒMBFLæŠ€æœ¯è€ƒè™‘è¯­å¥çš„æ‰§è¡Œæ˜¯å¦ä¼šå½±å“æµ‹è¯•[17]çš„ç»“æœã€‚å¦‚æœä¸€ä¸ªç¨‹åºè¯­å¥æ›´é¢‘ç¹åœ°å½±å“å¤±è´¥çš„æµ‹è¯•ï¼Œæ›´å°‘åœ°å½±å“é€šè¿‡çš„æµ‹è¯•ï¼Œé‚£ä¹ˆå®ƒå°±æ›´å€¼å¾—æ€€ç–‘ã€‚

A mutant is said to be killed by a test case if the test case has different execution results on the mutant and the original program [34]. A test case that kills mutants may carry diagnostic information. MBFL injects mutants into the program under test. MUSE [5] and Metallaxis-FL [4] are two state-of-the-art MBFL techniques. For a statement s, a MBFL technique:

å¦‚æœæµ‹è¯•ç”¨ä¾‹å¯¹çªå˜ä½“å’ŒåŸå§‹ç¨‹åº[34]æœ‰ä¸åŒçš„æ‰§è¡Œç»“æœï¼Œåˆ™çªå˜ä½“è¢«æµ‹è¯•ç”¨ä¾‹æ€æ­»ã€‚æ€æ­»çªå˜ä½“çš„æµ‹è¯•ç”¨ä¾‹å¯èƒ½æºå¸¦è¯Šæ–­ä¿¡æ¯ã€‚MBFLå°†çªå˜ä½“æ³¨å…¥è¢«æµ‹ç¨‹åºã€‚MUSE[5]å’ŒMetallaxis-FL[4]æ˜¯ä¸¤ç§æœ€å…ˆè¿›çš„MBFLæŠ€æœ¯ã€‚å¯¹äºä¸€ä¸ªè¯­å¥s, MBFLæŠ€æœ¯:

...

### 2.3 Program Slicing

A program slice is a subset of program elements that potentially affect the slicing criterion: a set of specific variables [35]. For example, a slicing criterion could be a pair hl, V i, where l is a program location and V is a set of variables. Program slicing determines the program elements that have a direct or indirect effect on the values of variables in V at the program location l. 
Program slicing was introduced as a debugging tool to reduce a program to a minimal form while still maintaining a given behavior [36]. Static slicing only uses the source code and accounts for all possible executions of the program. 
Dynamic slicing focuses on one execution for a specific input [37]. A dynamic slice contains all statements that may affect the values in the slicing criterion for a specific execution. The key difference between dynamic slicing and static slicing is that dynamic slicing only includes executed statements for specific input, but static slicing includes possiblyexecuted statements for all potential inputs. Since dynamic slices are significantly smaller, they are more suitable and effective for program debugging [38]. 
The following example shows the difference between static slicing and dynamic slicing.

ç¨‹åºåˆ‡ç‰‡æ˜¯å¯èƒ½å½±å“åˆ‡ç‰‡æ¡ä»¶çš„ç¨‹åºå…ƒç´ çš„å­é›†:ä¸€ç»„ç‰¹å®šçš„å˜é‡[35]ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªåˆ‡ç‰‡æ ‡å‡†å¯ä»¥æ˜¯ä¸€å¯¹hl, V iï¼Œå…¶ä¸­læ˜¯ä¸€ä¸ªç¨‹åºä½ç½®ï¼ŒVæ˜¯ä¸€ç»„å˜é‡ã€‚ç¨‹åºåˆ‡ç‰‡ç¡®å®šå¯¹ç¨‹åºä½ç½®lä¸Šçš„Vä¸­çš„å˜é‡å€¼æœ‰ç›´æ¥æˆ–é—´æ¥å½±å“çš„ç¨‹åºå…ƒç´ ã€‚

ç¨‹åºåˆ‡ç‰‡æ˜¯ä½œä¸ºä¸€ç§è°ƒè¯•å·¥å…·å¼•å…¥çš„ï¼Œå®ƒå¯ä»¥åœ¨ä¿æŒç»™å®šè¡Œä¸º[36]çš„åŒæ—¶å°†ç¨‹åºç¼©å‡åˆ°æœ€å°çš„å½¢å¼ã€‚é™æ€åˆ‡ç‰‡ä»…ä½¿ç”¨æºä»£ç å’Œå¸æˆ·çš„æ‰€æœ‰å¯èƒ½æ‰§è¡Œçš„ç¨‹åºã€‚

åŠ¨æ€åˆ‡ç‰‡ä¸»è¦å…³æ³¨ç‰¹å®šè¾“å…¥[37]çš„ä¸€æ¬¡æ‰§è¡Œã€‚åŠ¨æ€åˆ‡ç‰‡åŒ…å«æ‰€æœ‰å¯èƒ½å½±å“ç‰¹å®šæ‰§è¡Œçš„åˆ‡ç‰‡æ¡ä»¶ä¸­çš„å€¼çš„è¯­å¥ã€‚åŠ¨æ€åˆ‡ç‰‡å’Œé™æ€åˆ‡ç‰‡ä¹‹é—´çš„å…³é”®åŒºåˆ«åœ¨äºï¼ŒåŠ¨æ€åˆ‡ç‰‡åªåŒ…å«é’ˆå¯¹ç‰¹å®šè¾“å…¥çš„å·²æ‰§è¡Œè¯­å¥ï¼Œè€Œé™æ€åˆ‡ç‰‡åŒ…å«é’ˆå¯¹æ‰€æœ‰æ½œåœ¨è¾“å…¥çš„å¯èƒ½å·²æ‰§è¡Œè¯­å¥ã€‚ç”±äºåŠ¨æ€ç‰‡è¦å°å¾—å¤šï¼Œæ‰€ä»¥å®ƒä»¬æ›´é€‚åˆç”¨äºç¨‹åºè°ƒè¯•[38]ã€‚

ä¸‹é¢çš„ç¤ºä¾‹å±•ç¤ºäº†é™æ€åˆ‡ç‰‡å’ŒåŠ¨æ€åˆ‡ç‰‡ä¹‹é—´çš„åŒºåˆ«ã€‚

### 2.4 Stack trace Analysis

A stack trace is the list of active stack frames during execution of a program. Each stack frame corresponds to a function call that has not yet returned. Stack traces are useful information sources for developers during debugging tasks. When the system crashes, the stack trace indicates the sequence of function calls and the point where the crash occurred.

å †æ ˆè·Ÿè¸ªæ˜¯ç¨‹åºæ‰§è¡ŒæœŸé—´æ´»åŠ¨å †æ ˆå¸§çš„åˆ—è¡¨ã€‚æ¯ä¸ªå †æ ˆå¸§å¯¹åº”ä¸€ä¸ªå°šæœªè¿”å›çš„å‡½æ•°è°ƒç”¨ã€‚å †æ ˆè·Ÿè¸ªæ˜¯å¼€å‘äººå‘˜åœ¨è°ƒè¯•ä»»åŠ¡æœŸé—´çš„æœ‰ç”¨ä¿¡æ¯æºã€‚å½“ç³»ç»Ÿå´©æºƒæ—¶ï¼Œå †æ ˆè·Ÿè¸ªæŒ‡ç¤ºå‡½æ•°è°ƒç”¨çš„é¡ºåºå’Œå´©æºƒå‘ç”Ÿçš„ä½ç½®ã€‚

### 2.5 Predicate Switching

Predicate switching [10] is a fault localization technique designed for the faults related to control flow. A predicate, or conditional expression, controls the execution of different branches. If a failed test case can be changed to a passed test case by modifying the evaluated result of a predicate, the predicate is called a critical predicate and may be the root cause of the fault. 

The technique first traces the execution of the failed test and identifies all instances of branch predicates. Then it repeatedly re-runs the test, forcibly switching the outcome of a different predicate each time. Once switching a predicate produces the correct output, it reports this predicate as a critical predicate. The critical predicate is potentially the cause of the fault.

Predicate switching seems to be similar to MBFL techniques, as they both apply mutations and examine the change of the execution results. However, we still treat predicate switching as a different family because predicate switching mutates program states rather than the program itself. For example, if a conditional expression has been evaluated multiple times during the program execution, predicate switching inverses one evaluation at a time instead of all evaluations. Furthermore, the existing works [17], [26] do not include predicate switching as an MBFL approach as far as we are aware.

è°“è¯åˆ‡æ¢[10]æ˜¯é’ˆå¯¹ä¸æ§åˆ¶æµç›¸å…³çš„æ•…éšœè€Œè®¾è®¡çš„æ•…éšœå®šä½æŠ€æœ¯ã€‚è°“è¯æˆ–æ¡ä»¶è¡¨è¾¾å¼æ§åˆ¶ä¸åŒåˆ†æ”¯çš„æ‰§è¡Œã€‚å¦‚æœé€šè¿‡ä¿®æ”¹è°“è¯çš„è®¡ç®—ç»“æœå¯ä»¥å°†å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹æ›´æ”¹ä¸ºé€šè¿‡çš„æµ‹è¯•ç”¨ä¾‹ï¼Œåˆ™è¯¥è°“è¯ç§°ä¸ºä¸´ç•Œè°“è¯ï¼Œå®ƒå¯èƒ½æ˜¯æ•…éšœçš„æ ¹æœ¬åŸå› ã€‚

è¯¥æŠ€æœ¯é¦–å…ˆè·Ÿè¸ªå¤±è´¥æµ‹è¯•çš„æ‰§è¡Œï¼Œå¹¶æ ‡è¯†åˆ†æ”¯è°“è¯çš„æ‰€æœ‰å®ä¾‹ã€‚ç„¶åå®ƒé‡å¤åœ°é‡æ–°è¿è¡Œæµ‹è¯•ï¼Œå¼ºåˆ¶æ¯æ¬¡åˆ‡æ¢ä¸åŒè°“è¯çš„ç»“æœã€‚ä¸€æ—¦åˆ‡æ¢ä¸€ä¸ªè°“è¯äº§ç”Ÿæ­£ç¡®çš„è¾“å‡ºï¼Œå®ƒå°±å°†è¿™ä¸ªè°“è¯æŠ¥å‘Šä¸ºä¸€ä¸ªä¸´ç•Œè°“è¯ã€‚ä¸´ç•Œè°“è¯å¯èƒ½æ˜¯æ•…éšœçš„åŸå› ã€‚

è°“è¯åˆ‡æ¢ä¼¼ä¹ç±»ä¼¼äºMBFLæŠ€æœ¯ï¼Œå› ä¸ºå®ƒä»¬éƒ½åº”ç”¨äº†çªå˜å¹¶æ£€æŸ¥æ‰§è¡Œç»“æœçš„å˜åŒ–ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬ä»ç„¶å°†è°“è¯åˆ‡æ¢è§†ä¸ºä¸€ä¸ªä¸åŒçš„å®¶æ—ï¼Œå› ä¸ºè°“è¯åˆ‡æ¢ä½¿ç¨‹åºçŠ¶æ€å‘ç”Ÿçªå˜ï¼Œè€Œä¸æ˜¯ç¨‹åºæœ¬èº«ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€ä¸ªæ¡ä»¶è¡¨è¾¾å¼åœ¨ç¨‹åºæ‰§è¡ŒæœŸé—´è¢«æ±‚å€¼å¤šæ¬¡ï¼Œåˆ™è°“è¯åˆ‡æ¢ä¸€æ¬¡ä¸ä¸€ä¸ªæ±‚å€¼ç›¸åï¼Œè€Œä¸æ˜¯ä¸æ‰€æœ‰æ±‚å€¼ç›¸åã€‚æ­¤å¤–ï¼Œç°æœ‰çš„å·¥ä½œ[17]ï¼Œ[26]ä¸åŒ…æ‹¬è°“è¯åˆ‡æ¢ä½œä¸ºMBFLçš„æ–¹æ³•ï¼Œæ®æˆ‘ä»¬æ‰€çŸ¥ã€‚

### 2.6 Information Retrieval-Based Fault Localization

The early goals of Information retrieval (IR) area are indexing text and searching for useful documents in a collection [39]. Recently, some studies [11], [27], [40] have applied information retrieval techniques to fault localization. These approaches take as input a bug report, rather than a set of test cases, and generates as output a list of relevant source code files [41].

These approaches treat the bug reports as a query and then rank the source code files by their relevance to the query. Unlike aforementioned fault localization families, IRbased fault localization techniques do not require program execution information, such as passed and failed test cases. They locate relevant files based on the bug report [11].

ä¿¡æ¯æ£€ç´¢(IR)é¢†åŸŸçš„æ—©æœŸç›®æ ‡æ˜¯ç´¢å¼•æ–‡æœ¬å’Œåœ¨é›†åˆ[39]ä¸­æœç´¢æœ‰ç”¨çš„æ–‡æ¡£ã€‚è¿‘å¹´æ¥ï¼Œ[11]ã€[27]ã€[40]ç­‰ç ”ç©¶å°†ä¿¡æ¯æ£€ç´¢æŠ€æœ¯åº”ç”¨äºæ•…éšœå®šä½ã€‚è¿™äº›æ–¹æ³•å°†é”™è¯¯æŠ¥å‘Šä½œä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯ä¸€ç»„æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶ç”Ÿæˆç›¸å…³æºä»£ç æ–‡ä»¶[41]çš„åˆ—è¡¨ä½œä¸ºè¾“å‡ºã€‚

è¿™äº›æ–¹æ³•å°†é”™è¯¯æŠ¥å‘Šè§†ä¸ºæŸ¥è¯¢ï¼Œç„¶åæ ¹æ®å…¶ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹æºä»£ç æ–‡ä»¶è¿›è¡Œæ’åºã€‚ä¸å‰é¢æåˆ°çš„æ•…éšœå®šä½ç³»åˆ—ä¸åŒï¼ŒåŸºäºIRbasedçš„æ•…éšœå®šä½æŠ€æœ¯ä¸éœ€è¦ç¨‹åºæ‰§è¡Œä¿¡æ¯ï¼Œä¾‹å¦‚é€šè¿‡å’Œå¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹ã€‚ä»–ä»¬æ ¹æ®é”™è¯¯æŠ¥å‘Š[11]å®šä½ç›¸å…³æ–‡ä»¶ã€‚

### 2.7 History-Based Fault Localization

As a general rule, program files that contained more bugs in the past are likely to have more bugs in the future [42]. Development history can be used for fault prediction, which ranks the elements in a program by their likelihood to be defective before any failure has been discovered [12]. Traditionally, fault prediction and fault localization are considered as different problems. However, since they both produce a list of suspicious elements, we also consider fault prediction techniques in this paper.

In particular, we consider a simple fault prediction technique introduced by Rahman et al. [13]. This technique simply ranks files by the number of fixing changes applied on them. This simple technique has the same utility for inspections as a more sophisticated fault prediction technique FixCache [12].

ä¸€èˆ¬æ¥è¯´ï¼Œè¿‡å»åŒ…å«æ›´å¤šbugçš„ç¨‹åºæ–‡ä»¶åœ¨æœªæ¥[42]ä¸­å¯èƒ½ä¼šæœ‰æ›´å¤šbugã€‚å¼€å‘å†å²å¯ç”¨äºæ•…éšœé¢„æµ‹ï¼Œå³åœ¨å‘ç°ä»»ä½•æ•…éšœä¹‹å‰ï¼Œæ ¹æ®ç¨‹åºä¸­å…ƒç´ çš„ç¼ºé™·å¯èƒ½æ€§å¯¹å…¶è¿›è¡Œæ’åºã€‚ä¼ ç»Ÿä¸Šï¼Œæ•…éšœé¢„æµ‹å’Œæ•…éšœå®šä½è¢«è®¤ä¸ºæ˜¯ä¸¤ä¸ªä¸åŒçš„é—®é¢˜ã€‚ç„¶è€Œï¼Œç”±äºå®ƒä»¬éƒ½äº§ç”Ÿäº†ä¸€ç³»åˆ—çš„å¯ç–‘å…ƒç´ ï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­ä¹Ÿè€ƒè™‘äº†æ•…éšœé¢„æµ‹æŠ€æœ¯ã€‚

ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬è€ƒè™‘äº†Rahmanç­‰äººæå‡ºçš„ä¸€ç§ç®€å•çš„æ•…éšœé¢„æµ‹æŠ€æœ¯ã€‚è¿™ç§æŠ€æœ¯åªæ˜¯æ ¹æ®åº”ç”¨äºæ–‡ä»¶ä¸Šçš„ä¿®å¤æ›´æ”¹çš„æ•°é‡å¯¹æ–‡ä»¶è¿›è¡Œæ’åºã€‚è¿™ä¸ªç®€å•çš„æŠ€æœ¯ä¸æ›´å¤æ‚çš„æ•…éšœé¢„æµ‹æŠ€æœ¯FixCache[12]å…·æœ‰ç›¸åŒçš„æ£€æŸ¥åŠŸèƒ½ã€‚

### 2.8 Learning to Rank

Learning to rank techniques train a machine learning model for a ranking task [43]. Learning to rank is widely used in Information Retrieval (IR) and Natural Language Processing (NLP) [44]. For example, in document retrieval, the task is to sort documents by the relevance to a query. One way to create the ranking model is with expert knowledge. By contrast, learning to rank techniques improve ranking performance and automatically create the ranking model, integrating many features (or signals).

å­¦ä¹ æ’åºæŠ€æœ¯è®­ç»ƒäº†ä¸€ä¸ªç”¨äºæ’åºä»»åŠ¡[43]çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚å­¦ä¹ æ’åºåœ¨ä¿¡æ¯æ£€ç´¢(IR)å’Œè‡ªç„¶è¯­è¨€å¤„ç†(NLP)[44]ä¸­å¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨æ–‡æ¡£æ£€ç´¢ä¸­ï¼Œä»»åŠ¡æ˜¯æ ¹æ®ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§å¯¹æ–‡æ¡£è¿›è¡Œæ’åºã€‚åˆ›å»ºæ’åæ¨¡å‹çš„ä¸€ç§æ–¹æ³•æ˜¯åˆ©ç”¨ä¸“å®¶çŸ¥è¯†ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå­¦ä¹ æ’åæŠ€æœ¯å¯ä»¥æé«˜æ’åæ€§èƒ½ï¼Œå¹¶è‡ªåŠ¨åˆ›å»ºæ’åæ¨¡å‹ï¼Œé›†æˆäº†è®¸å¤šç‰¹æ€§(æˆ–ä¿¡å·)ã€‚

Liu categorized learning to rank models into three groups [44]. Pointwise techniques transform the rank problem into a regression or ordinal classification problem for the ordinal score in the training data. Pairwise techniques approximate the problem by a classification problem: creating a classifier for classifying item pairs according to their ordinal position. The goal of pairwise techniques is to minimize ordinal inversions. Listwise techniques take ranking lists as input and evaluate the ranking lists directly by the loss functions.

åˆ˜å°†æ¨¡å‹çš„å­¦ä¹ åˆ†æˆä¸‰ç»„[44]ã€‚ç‚¹æ€åŒ–æŠ€æœ¯å°†ç§©é—®é¢˜è½¬åŒ–ä¸ºè®­ç»ƒæ•°æ®ä¸­åºæ•°åˆ†æ•°çš„å›å½’æˆ–åºæ•°åˆ†ç±»é—®é¢˜ã€‚ä¸¤ä¸¤é…å¯¹æŠ€æœ¯é€šè¿‡ä¸€ä¸ªåˆ†ç±»é—®é¢˜æ¥è¿‘ä¼¼è¿™ä¸ªé—®é¢˜:åˆ›å»ºä¸€ä¸ªåˆ†ç±»å™¨ï¼Œæ ¹æ®å®ƒä»¬çš„åºå·ä½ç½®å¯¹é¡¹ç›®å¯¹è¿›è¡Œåˆ†ç±»ã€‚ä¸¤ä¸¤é…å¯¹æŠ€æœ¯çš„ç›®æ ‡æ˜¯æœ€å°åŒ–åºå¯¹åè½¬ã€‚åˆ—è¡¨æŠ€æœ¯ä»¥æ’åºåˆ—è¡¨ä¸ºè¾“å…¥ï¼Œåˆ©ç”¨æŸå¤±å‡½æ•°ç›´æ¥å¯¹æ’åºåˆ—è¡¨è¿›è¡Œè¯„ä¼°ã€‚

Recently, Xuan and Monperrus showed that learning to rank model can be used to combine different formulae in SBFL [23]. The basic idea is to treat the suspiciousness score produced by different formulae as features and use learning to rank to find a model that ranks the faulty element as high as possible. In this paper we apply learning to rank similarly to combine approaches from different families.

æœ€è¿‘ï¼ŒXuanå’ŒMonperrusè¯æ˜äº†å­¦ä¹ rankæ¨¡å‹å¯ä»¥ç”¨äºç»„åˆSBFL[23]ä¸­ä¸åŒçš„å…¬å¼ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯å°†ä¸åŒå…¬å¼æ‰€äº§ç”Ÿçš„å¯ç–‘æ€§åˆ†æ•°ä½œä¸ºç‰¹å¾ï¼Œåˆ©ç”¨å­¦ä¹ æ’åºçš„æ–¹æ³•ï¼Œæ‰¾åˆ°ä¸€ä¸ªå°†é”™è¯¯å…ƒç´ å°½å¯èƒ½é«˜çš„æ’åºæ¨¡å‹ã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ åº”ç”¨äºç›¸ä¼¼çš„æ’åºï¼Œä»¥ç»“åˆæ¥è‡ªä¸åŒå®¶åº­çš„æ–¹æ³•ã€‚
