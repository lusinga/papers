# HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face

- Yongliang Shen
- Kaitao Song
- Xu Tan
- Dongsheng Li
- Weiming Lu
- Yueting Zhuang
Zhejiang University1, Microsoft Research Asia2
{syl, luwm, yzhuang}@zju.edu.cn, {kaitaosong, xuta, dongsli}@microsoft.com

## Abstract

Solving complicated AI tasks with different domains and modalities is a key step toward advanced artificial intelligence. While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a framework that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards advanced artificial intelligence.

解决不同领域和模态的复杂人工智能任务是实现高级人工智能的关键步骤。虽然有很多人工智能模型可用于不同的领域和模态，但它们不能处理复杂的人工智能任务。考虑到大型语言模型（LLMs）在语言理解、生成、交互和推理方面表现出了非凡的能力，我们主张LLMs可以作为一个控制器，管理现有的人工智能模型，以解决复杂的人工智能任务，而语言可以是一个通用的接口，来赋能这一过程。基于这一理念，我们提出了HuggingGPT，一个利用LLMs（例如ChatGPT）连接机器学习社区（例如Hugging Face）中各种人工智能模型来解决人工智能任务的框架。具体来说，我们使用ChatGPT在接收到用户请求时进行任务规划，根据Hugging Face中可用的功能描述选择模型，使用选定的人工智能模型执行每个子任务，并根据执行结果总结响应。通过利用ChatGPT的强大语言能力和Hugging Face中丰富的人工智能模型，HuggingGPT能够涵盖不同模态和领域中众多复杂的人工智能任务，并在语言、视觉、语音等具有挑战性的任务上取得了令人印象深刻的结果，为高级人工智能开辟了一条新的道路。

## 1 Introduction

Large language models (LLMs) [1, 2, 3, 4, 5, 6], such as ChatGPT, have attracted enormous attentions from both academia and industry, due to their remarkable performance on various natural language processing (NLP) tasks. Based on large-scale pre-training on massive text corpora and reinforcement learning from human feedback (RLHF), LLMs can produce superior capability in language understanding, generation, interaction, and reasoning. The powerful capability of LLMs also drives many emergent research topics (e.g., in-context learning [1, 7, 8], instruction learning [9, 10, 11, 12], and chain-of-thought prompting [13, 14, 15, 16]) to further investigate the huge potential of LLMs, and brings unlimited possibilities for us to build advanced artificial intelligence systems.

大型语言模型（LLMs）[1, 2, 3, 4, 5, 6]，如 ChatGPT，由于其在各种自然语言处理（NLP）任务上的卓越性能，受到了学术界和工业界的巨大关注。基于大规模文本语料库的预训练和人类反馈的强化学习（RLHF），LLMs 可以在语言理解、生成、交互和推理方面产生出色的能力。LLMs 的强大能力也推动了许多新兴的研究主题（例如，上下文学习[1, 7, 8]，指令学习[9, 10, 11, 12]，和思维链提示[13, 14, 15, 16]），以进一步探索 LLMs 的巨大潜力，并为我们构建先进的人工智能系统带来无限的可能性。

Despite these great successes, current LLM technologies are still imperfect and confront some urgent challenges on the way to building an advanced AI system. We discuss them from these aspects: 1) Limited to the input and output forms of text generation, current LLMs lack the ability to process complex information such as vision and speech, regardless of their significant achievements in NLP tasks; 2) In real-world scenarios, some complex tasks are usually composed of multiple sub-tasks, and thus require the scheduling and cooperation of multiple models, which are also beyond the capability of language models; 3) For some challenging tasks, LLMs demonstrate excellent results in zero-shot or few-shot settings, but they are still weaker than some experts (e.g., fine-tuned models). How to address these issues could be the first and also critical step for LLMs toward more advanced AI systems.

尽管取得了这些巨大的成功，当前的 LLM 技术仍然不完善，面临着在构建先进的 AI 系统的道路上一些紧迫的挑战。我们从以下几个方面讨论它们：1）受限于文本生成的输入和输出形式，当前的 LLMs 缺乏处理视觉和语音等复杂信息的能力，尽管它们在 NLP 任务上取得了显著的成就；2）在现实世界的场景中，一些复杂的任务通常由多个子任务组成，因此需要多个模型的调度和协作，这也超出了语言模型的能力范围；3）对于一些具有挑战性的任务，LLMs 在零样本或少样本设置下表现出优异的结果，但它们仍然比一些专家（例如，微调过的模型）弱。如何解决这些问题可能是 LLMs 向更先进的 AI 系统迈进的第一步，也是至关重要的一步。

In this paper, we point out that in order to handle complicated AI tasks, LLMs should be able to coordinate with external models to utilize their powers. So, the key point is how to choose suitable middleware to bridge the connections between LLMs and AI models. To address this problem, we notice that each AI model can be denoted as a form of language by summarizing its model function. Therefore, we introduce a concept: “Language is a generic interface for LLMs to connect AI models”. In other words, by incorporating these model descriptions into prompts, LLMs can be considered as the brain to manage AI models such as planning, scheduling, and cooperation. As a result, this strategy enables LLMs to invoke external models for solving AI tasks. But if we want to integrate multiple AI models into LLMs, another challenge will arise: solving numerous AI tasks needs collecting a large number of high-quality model descriptions, which requires heavy prompt engineering. Coincidentally, we notice that some public ML communities usually offer a wide variety of applicable models with well-defined model descriptions for solving specific AI tasks such as language, vision, and speech. These observations bring us some inspiration: Can we link LLMs (e.g., ChatGPT) with public ML communities (e.g., GitHub, Hugging Face 3, Azure, etc) for solving complex AI tasks via a language-based interface?

在本文中，我们指出为了处理复杂的 AI 任务，大型语言模型（LLMs）应能够与外部模型协同工作，充分发挥它们的能力。因此，关键问题在于如何选择合适的中间件来构建 LLMs 和 AI 模型之间的连接。为解决这个问题，我们注意到每个 AI 模型都可以通过概括其模型功能来表示为一种语言形式。因此，我们引入了一个概念：“语言是 LLMs 连接 AI 模型的通用接口”。换句话说，通过将这些模型描述整合到提示中，LLMs 可以被视为管理 AI 模型（如计划、调度和合作）的大脑。因此，这种策略使得 LLMs 能够调用外部模型来解决 AI 任务。但是，如果我们想将多个 AI 模型整合到 LLMs 中，还将面临另一个挑战：解决众多 AI 任务需要收集大量高质量的模型描述，这需要大量的提示工程。巧合的是，我们注意到一些公共机器学习社区通常为解决特定 AI 任务（如语言、视觉和语音）提供了各种适用的模型，并附有详细的模型描述。这些观察给我们带来了一些启示：我们能否通过基于语言的接口，将 LLMs（例如 ChatGPT）与公共机器学习社区（例如 GitHub、Hugging Face 3、Azure 等）链接起来，以解决复杂的 AI 任务？

Therefore, in this paper, we propose a system called HuggingGPT to connect LLMs (i.e., ChatGPT) and ML community (i.e., Hugging Face), which can process inputs from different modalities and solve numerous complex AI tasks. More specifically, for each AI model in Hugging Face, we use its corresponding model description from the library and fuse it into the prompt to establish the connection with ChatGPT. Afterward, in our system, LLMs (i.e., ChatGPT) will act as the brain to determine the answers to the questions of users. Just as shown in Figure 1, the whole process of HuggingGPT can be divided into four stages:

因此，在本文中，我们提出了一个名为 HuggingGPT 的系统，将 LLMs（即 ChatGPT）和 ML 社区（即 Hugging Face）连接起来，可以处理来自不同模态的输入并解决众多复杂的 AI 任务。更具体地说，对于 Hugging Face 中的每个 AI 模型，我们使用其在库中的相应模型描述，并将其融入提示以建立与 ChatGPT 的连接。之后，在我们的系统中，LLMs（即 ChatGPT）将充当大脑，确定用户问题的答案。如图 1 所示，HuggingGPT 的整个过程可以分为四个阶段：

