# A Survey on Automated Log Analysis for Reliability Engineering

Logs are semi-structured text generated by logging statements in software source code. In recent decades, software logs have become imperative in the reliability assurance mechanism of many software systems, because they are often the only data available that record software runtime information. As modern software is evolving into a large scale, the volume of logs has increased rapidly. To enable effective and efficient usage of modern software logs in reliability engineering, a number of studies have been conducted on automated log analysis. This survey presents a detailed overview of automated log analysis research, including how to automate and assist the writing of logging statements, how to compress logs, how to parse logs into structured event templates, and how to employ logs to detect anomalies, predict failures, and facilitate diagnosis. Additionally, we survey work that releases open-source toolkits and datasets. Based on the discussion of the recent advances, we present several promising future directions toward real-world and next-generation automated log analysis.

日志是由软件源代码中的日志语句生成的半结构化文本。近几十年来，软件日志在许多软件系统的可靠性保证机制中变得必不可少，因为它们通常是记录软件运行时信息的唯一可用数据。随着现代软件向大规模演进，日志量迅速增加。为了在可靠性工程中有效和高效地使用现代软件日志，已经对自动日志分析进行了大量研究。本次调查详细介绍了自动化日志分析研究，包括如何自动化和辅助编写日志语句、如何压缩日志、如何将日志解析为结构化的事件模板，以及如何利用日志来检测异常、预测故障、并方便诊断。此外，我们还调查了发布开源工具包和数据集的工作。基于对最新进展的讨论，我们提出了几个有希望的未来方向，即现实世界和下一代自动日志分析。

## 1 INTRODUCTION

In the recent decades, modern software, such as search engines, instant messaging apps, and cloud systems, has been increasingly integrated into our daily lives and become indispensable. Most of these software systems are expected to be available on a 24/7 basis. Any non-trivial downtime can lead to significant revenue loss, especially for large-scale distributed systems [52, 53, 172]. For example, in 2017, a downtime in Amazon led to a loss of 150+ million U.S. dollars [173]. Thus, the reliability of modern software is of paramount importance [130].

近几十年来，搜索引擎、即时通讯应用程序和云系统等现代软件越来越多地融入我们的日常生活，变得不可或缺。 这些软件系统中的大多数预计将在 24/7 的基础上提供。 任何非平凡的停机时间都可能导致重大的收入损失，尤其是对于大型分布式系统 [52, 53, 172]。 例如，2017 年亚马逊的一次宕机导致损失超过 1.5 亿美元 [173]。 因此，现代软件的可靠性至关重要[130]。

Software logs have been widely employed in a variety of reliability assurance tasks, because they are often the only data available that record software runtime information. Additionally, logs also play an indispensable role in data-driven decision making in industry [149]. In general, logs are semi-structured text printed by logging statements (e.g., printf(), logger.info()) in the source code. For example, in Figure 1, the two log messages are printed by the two logging statements in the source code. The first few words (e.g., “Wombat”) of the log messages are decided by the corresponding logging framework (e.g., SLF4J) and they are in structured form. On the contrary, the remaining words (e.g., “50 degrees”) are unstructured, because they are written by developers to describe specific system runtime events.

软件日志已广泛用于各种可靠性保证任务，因为它们通常是记录软件运行时信息的唯一可用数据。 此外，日志在工业数据驱动决策中也发挥着不可或缺的作用 [149]。 通常，日志是由源代码中的日志语句（例如 printf()、logger.info()）打印的半结构化文本。 例如，在图 1 中，源代码中的两条日志语句打印了两条日志消息。 日志消息的前几个词（例如“Wombat”）由相应的日志框架（例如 SLF4J）决定，并且它们是结构化的。 相反，其余的词（例如，“50 度”）是非结构化的，因为它们是由开发人员编写的，用于描述特定的系统运行时事件。

A typical log analysis management framework is illustrated by the upper part of Figure 2. Particularly, traditional logging practice (e.g., which variables to print) mainly relies on developers’ domain knowledge. During system runtime, software logs are collected and compressed as normal files using file compression toolkits [110] (e.g., WinRAR). Additionally, developers leverage the collected logs in various reliability assurance tasks (i.e., log mining), such as anomaly detection. Decades ago, these processes were based on specific rules specified by the developers. For example, to extract specific information related to a task (e.g., thread ID), developers need to design regex (i.e., regular expression) rules for automated log parsing [76]. The traditional anomaly detection process also relies on manually constructed rules [66]. These log analysis techniques were effective at the beginning, because most of the widely used software systems were small and simple.

图 2 上半部分说明了一个典型的日志分析管理框架。 特别是，传统的日志记录实践（例如，打印哪些变量）主要依赖于开发人员的领域知识。 在系统运行期间，使用文件压缩工具包 [110]（例如 WinRAR）收集软件日志并将其压缩为普通文件。 此外，开发人员在各种可靠性保证任务（即日志挖掘）中利用收集的日志，例如异常检测。 几十年前，这些流程基于开发人员指定的特定规则。 例如，为了提取与任务相关的特定信息（例如线程 ID），开发人员需要设计用于自动日志解析的正则表达式（即正则表达式）规则 [76]。 传统的异常检测过程也依赖于人工构建的规则[66]。 这些日志分析技术一开始是有效的，因为大多数广泛使用的软件系统都是小而简单的。

However, as modern software has become much larger in scale and more complex in structure, traditional log analysis that is mainly based on ad hoc domain knowledge or manually constructed and maintained rules becomes inefficient and ineffective [146]. This brings four major challenges to modern log analysis. (1) In many practices, while a number of senior developers in the same group share some best logging practices, most of the new developers or developers from different projects write logging statements based on domain knowledge and ad-hoc designs. As a result, the quality of the runtime logs varies to a large extent. (2) The volume of software logs has increased rapidly (e.g., 50 GB/h [138]). Consequently, it is much more difficult to manually dig out the rules (e.g., log event templates or anomalous patterns). (3) With the prevalence ofWeb service and source code sharing platforms (e.g., Github), software could be written by hundreds of global developers. Developers who should maintain the rules often have no idea of the original logging purpose, which further increases the difficulty in manual maintenance of their rules. (4) Due to the wide adoption of the agile software development concept, a new software version often comes in a short term manner. Thus, corresponding logging statements update frequently as well (e.g., hundreds of new logging statements per month [178]). However, it is hard for developers to manually update the rules.

然而，随着现代软件规模越来越大，结构越来越复杂，主要基于特定领域知识或手动构建和维护规则的传统日志分析变得低效和无效[146]。这给现代日志分析带来了四大挑战。 (1) 在许多实践中，虽然同一组中的一些高级开发人员共享一些最佳日志实践，但大多数新开发人员或来自不同项目的开发人员根据领域知识和临时设计编写日志语句。因此，运行时日志的质量差异很大。 (2) 软件日志量快速增长（例如 50 GB/h [138]）。因此，手动挖掘规则（例如，日志事件模板或异常模式）要困难得多。 (3) 随着 Web 服务和源代码共享平台（例如 Github）的流行，软件可以由数百名全球开发人员编写。应该维护规则的开发者往往不知道最初的日志目的，这进一步增加了他们手动维护规则的难度。 (4) 由于敏捷软件开发理念的广泛采用，新的软件版本往往在短期内出现。因此，相应的日志语句也会频繁更新（例如，每月有数百个新的日志语句 [178]）。但是，开发人员很难手动更新规则。

To address these challenges, a great amount of work has been accomplished by both researchers and practitioners in recent decades. In particular, starting from 2003, a line of research efforts have been contributed to automated rule construction and critical information extraction from software logs, including the first pieces of work of log parsing [174], anomaly detection [174], and failure prediction [157]. In addition, in the same year, Hätönen et al. [70] proposed the first log specific compression technique. Later, many empirical studies were conducted as the first steps toward some difficult problems in automated log analysis, including the first study on failure diagnosis by Jiang et al. [83] in 2009, the first exploration of logging practice by Yuan et al. [189] in 2012, and the first industrial study on logging practice by Fu et al. [58] in 2014. Recently, machine learning and deep learning algorithms have been widely adopted by the state-of-the-art (SOTA) papers, such as the deep learning–based “what-to-log” approach [102] in logging practice and Deeplog [46] in anomaly detection. Besides machine learning, parallelization has been employed in various recent papers, such as Logzip [110] in log compression and POP [72] in log parsing.

为了应对这些挑战，近几十年来，研究人员和从业人员都完成了大量工作。特别是，从 2003 年开始，一系列研究工作已经为自动规则构建和从软件日志中提取关键信息做出了贡献，包括日志解析 [174]、异常检测 [174] 和故障预测的第一批工作 [174]。 157]。此外，同年，Hätönen 等人。 [70] 提出了第一个日志特定压缩技术。后来，许多实证研究作为解决自动化日志分析中一些难题的第一步，包括蒋等人对故障诊断的首次研究。 [83] 2009年，袁等人首次对测井实践进行探索。 [189] 在 2012 年，以及 Fu 等人的第一个伐木实践工业研究。 [58] 在 2014 年。最近，机器学习和深度学习算法已被最先进的 (SOTA) 论文广泛采用，例如基于深度学习的“记录内容”方法 [102]在日志实践中和 Deeplog [46] 在异常检测中。除了机器学习之外，并行化已在最近的各种论文中使用，例如日志压缩中的 Logzip [110] 和日志解析中的 POP [72]。

These extensive studies on automated log analysis across multiple core directions have largely boosted the effectiveness and efficiency of systematic usage of software logs. However, the diversity and richness of both the research directions and recent papers could inevitably hinder the non-experts who intend to understand the SOTA and propose further improvements. To address this problem, this article surveys 158 papers from the past 23 years across a variety of topics in log analysis. The papers under exploration are mainly from top venues in three related fields: software engineering (e.g., ICSE), system (e.g., SOSP), and networking (e.g., NSDI). Thus, the readers can obtain a deep understanding of the advantages and limitations of the SOTA approaches, as well as taking a glance at the existing open-source toolkits and datasets. In addition, the insights and challenges summarized in the article can help practitioners understand the potential usage of the automated log analysis techniques in practice and realize the gap between academy and industry in this field. We present crucial research efforts on automated log analysis from the following seven perspectives as illustrated in Figure 2:

这些对跨多个核心方向的自动化日志分析的广泛研究在很大程度上提高了软件日志系统使用的有效性和效率。然而，研究方向和近期论文的多样性和丰富性不可避免地阻碍了非专家想要了解 SOTA 并提出进一步改进的建议。为了解决这个问题，本文调查了过去 23 年中的 158 篇论文，涉及日志分析的各种主题。探索中的论文主要来自三个相关领域的顶级会议：软件工程（例如ICSE）、系统（例如SOSP）和网络（例如NSDI）。因此，读者可以深入了解 SOTA 方法的优点和局限性，并浏览现有的开源工具包和数据集。此外，文章中总结的见解和挑战可以帮助从业者了解自动化日志分析技术在实践中的潜在用途，并认识到该领域学术界和工业界的差距。我们从以下七个角度介绍了有关自动化日志分析的重要研究工作，如图 2 所示：


## 2 SURVEY METHODOLOGY

## 3 LOGGING

Logging is the task of constructing logging statements with proper description and necessary program variables and inserting the logging statements to the right positions in the source code. Logging has attracted attention from both academia [139, 149, 158, 180] and industry [9, 18, 58, 149, 189, 194] across a variety of application domains, because logging is a fundamental step for all the subsequent log mining tasks.

日志是构建具有适当描述和必要程序变量的日志语句并将日志语句插入源代码中正确位置的任务。 日志在各种应用领域引起了学术界 [139, 149, 158, 180] 和工业界 [9, 18, 58, 149, 189, 194] 的关注，因为日志是所有后续日志挖掘的基本步骤 任务。

### 3.1 Logging Mechanism and Libraries

### 3.2 Challenges for Logging

### 3.3 Logging Approaches

## 4 LOG COMPRESSION

### 4.1 Challenges for Log Compression

### 4.2 Characteristics for Log Compression

### 4.3 Log Compression Approaches

## 5 LOG PARSING

After log collection, log messages will be input into different downstream log mining tasks (e.g., anomaly detection) for further analysis. However, most of the existing log mining tools [75, 180] require structured input data (e.g., a list of structured log events or a matrix). Thus, a crucial step of automated log analysis is to parse the semi-structured log messages into structured log events. Figure 4 presents a log parsing example, where the input is a log message collected from Hadoop Distributed File System (HDFS) [180]. A log message is composed of message header and message content. The message header is determined by the logging framework and thus it is relatively easy to extract, such as verbosity levels (e.g., “INFO”). In contrast, it is difficult to extract key information from the message content, because it is mainly written by developers in free-form natural language. Typically, the message content contains constants and variables. Constants are the fixed text written by the developers (e.g., “Received”) and describe a system event, while variables are the values of the program variables that carry dynamic runtime information. The goal of log parsing is to distinguish between constants and variables. All the constants form the event template. The output of a log parser is a structured log message, containing an event template and the key parameters.

日志收集后，日志消息将输入到不同的下游日志挖掘任务（例如，异常检测）中进行进一步分析。然而，大多数现有的日志挖掘工具 [75, 180] 需要结构化输入数据（例如，结构化日志事件列表或矩阵）。因此，自动化日志分析的一个关键步骤是将半结构化日志消息解析为结构化日志事件。图 4 展示了一个日志解析示例，其中输入是从 Hadoop 分布式文件系统 (HDFS) [180] 收集的日志消息。日志消息由消息头和消息内容组成。消息头由日志框架确定，因此相对容易提取，例如详细级别（例如，“INFO”）。相比之下，很难从消息内容中提取关键信息，因为它主要是由开发人员以自由形式的自然语言编写的。通常，消息内容包含常量和变量。常量是开发人员编写的固定文本（例如，“Received”）并描述系统事件，而变量是携带动态运行时信息的程序变量的值。日志解析的目标是区分常量和变量。所有常量构成了事件模板。日志解析器的输出是结构化日志消息，包含事件模板和关键参数。

### 5.1 Challenges for Log Parsing

### 5.2 Log Parser Characteristics

### 5.3 Offline Log Parsing Approaches

### 5.4 Online Log Parsing Approaches

## 6 LOG MINING

Log mining employs statistics, data mining, and machine learning techniques for automatically exploring and analyzing large volume of log data to glean meaningful patterns and informative trends. The extracted patterns and knowledge could guide and facilitate monitoring, administering, and troubleshooting of software systems. In this section, we first elaborate on challenges encountered in log mining (Section 6.1). Then,we describe the general workflow of log mining (Section 6.2). Finally, we introduce three major log mining tasks for reliability engineering, including anomaly detection (Section 6.3), failure prediction (Section 6.4), and failure diagnosis (Section 6.5). Other relevant studies with relatively lesser popularity are laid out in Section 6.6.

日志挖掘采用统计、数据挖掘和机器学习技术来自动探索和分析大量日志数据，以收集有意义的模式和信息趋势。 提取的模式和知识可以指导和促进软件系统的监控、管理和故障排除。 在本节中，我们首先详细说明日志挖掘中遇到的挑战（第 6.1 节）。 然后，我们描述了日志挖掘的一般工作流程（第 6.2 节）。 最后，我们介绍可靠性工程的三个主要日志挖掘任务，包括异常检测（第 6.3 节）、故障预测（第 6.4 节）和故障诊断（第 6.5 节）。 其他受欢迎程度相对较低的相关研究在第 6.6 节中列出。

### 6.1 Challenges of Log Mining

Traditionally, engineers perform simple keyword search (such as “error,” “exception,” and “failed”) to mine suspicious logs that might be associated with software problems, e.g., component failures. Some rule-based tools [66, 151, 155] have been developed to detect software problems by comparing logs against a set of manually defined rules that describe normal software behaviors. However, due to the ever-increasing volume, variety, and velocity of logs produced by modern software, such approaches fall short for being labor-intensive and error-prone. Moreover, suspicious logs are often overwhelmed by logs generated during software normal executions. Manually sifting through a massive amount of logs to identify failure-relevant ones is like finding a needle in a haystack.

传统上，工程师执行简单的关键字搜索（例如“错误”、“异常”和“失败”）来挖掘可能与软件问题（例如组件故障）相关的可疑日志。 已经开发了一些基于规则的工具 [66, 151, 155] 来通过将日志与一组描述正常软件行为的手动定义的规则进行比较来检测软件问题。 然而，由于现代软件产生的日志的数量、种类和速度不断增加，这种方法不具备劳动密集型和容易出错的特点。 此外，可疑日志经常被软件正常执行期间生成的日志所淹没。 手动筛选大量日志以识别与故障相关的日志就像大海捞针。

Additionally, inspecting logs for software troubleshooting often requires engineers to possess descent knowledge about the software. However, modern software systems usually consist of many components developed by different engineers, leading to the generation of heterogeneous logs, which makes troubleshooting beyond the ability of a single engineer. Moreover, due to the high complexity of modern software systems, failures could stem from various sources of software and hardware issues. Examples include software bugs, hardware damage, OS crash, service exception, and so on. In addition, promptly pinpointing to the root cause by inspecting logs highly relies on engineers’ expertise and experience. However, such knowledge is often not well accumulated, organized, and documented. Therefore, sophisticated ways to conduct automatic log mining are in high demand.

此外，检查日志以进行软件故障排除通常需要工程师具备有关软件的知识。 然而，现代软件系统通常由不同工程师开发的许多组件组成，导致生成异构日志，这使得故障排除超出了单个工程师的能力。 此外，由于现代软件系统的高度复杂性，故障可能源于软件和硬件问题的各种来源。 示例包括软件错误、硬件损坏、操作系统崩溃、服务异常等。 此外，通过检查日志及时查明根本原因高度依赖工程师的专业知识和经验。 然而，这些知识往往没有很好地积累、组织和记录。 因此，对进行自动日志挖掘的复杂方法的需求量很大。

### 6.2 A General Workflow of Log Mining

#### 6.2.1 Log Partition

#### 6.2.2 Feature Extraction

#### 6.2.3 Model Training

#### 6.2.4 Online Deployment

### 6.3 Anomaly Detection

### 6.4 Failure Prediction

### 6.5 Failure Diagnosis

## 7 OPEN-SOURCE TOOLKITS AND DATASETS

## 8 CONCLUSION

Recent years have witnessed the blossom of log analysis. Given the importance of software logs in reliability engineering, extensive efforts have been contributed to efficient and effective log analysis. This survey mainly explores the four main steps in automated log analysis framework: logging, log compression, log parsing, and log mining. Additionally, we introduce the available open-source toolkits and datasets. Our article enables the outsiders to step in this promising and practical field, and allows the experts to fill in the gaps of their knowledge background. Based on the investigation of these recent advances, we proposed new insights and discussed several future directions, including how to make automated log analysis more feasible under the modern agile and distributed development style, and the concept of a next-generation log analysis framework.

近年来见证了日志分析的蓬勃发展。 鉴于软件日志在可靠性工程中的重要性，已经为高效和有效的日志分析做出了广泛的努力。 本次调查主要探讨自动化日志分析框架的四个主要步骤：日志记录、日志压缩、日志解析和日志挖掘。 此外，我们还介绍了可用的开源工具包和数据集。 我们的文章让外行人能够踏入这个有前途且实用的领域，让专家们填补他们知识背景的空白。 基于对这些最新进展的调查，我们提出了新的见解并讨论了几个未来的方向，包括如何在现代敏捷和分布式开发风格下使自动化日志分析更加可行，以及下一代日志分析框架的概念。
